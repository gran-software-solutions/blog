"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[2099],{5680:(e,n,a)=>{a.d(n,{xA:()=>p,yg:()=>m});var t=a(6540);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function s(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),a.push.apply(a,t)}return a}function o(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?s(Object(a),!0).forEach(function(n){r(e,n,a[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))})}return e}function i(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},s=Object.keys(e);for(t=0;t<s.length;t++)a=s[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(t=0;t<s.length;t++)a=s[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=t.createContext({}),c=function(e){var n=t.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):o(o({},n),e)),a},p=function(e){var n=c(e.components);return t.createElement(l.Provider,{value:n},e.children)},u="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},d=t.forwardRef(function(e,n){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=c(a),d=r,m=u["".concat(l,".").concat(d)]||u[d]||g[d]||s;return a?t.createElement(m,o(o({ref:n},p),{},{components:a})):t.createElement(m,o({ref:n},p))});function m(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var s=a.length,o=new Array(s);o[0]=d;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i[u]="string"==typeof e?e:r,o[1]=i;for(var c=2;c<s;c++)o[c]=a[c];return t.createElement.apply(null,o)}return t.createElement.apply(null,a)}d.displayName="MDXCreateElement"},7650:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var t=a(8168),r=(a(6540),a(5680)),s=a(9041);const o={title:"Automating Production Postgres on Kubernetes: A PGO and Ansible IaC Pattern",authors:"gglazewskigran",tags:["k8s","ansible","postgresql","devops"],enableComments:!0},i=void 0,l={permalink:"/2025/07/14/a-pgo-and-ansible-iac-pattern",source:"@site/blog/2025-07-14-a-pgo-and-ansible-iac-pattern/index.mdx",title:"Automating Production Postgres on Kubernetes: A PGO and Ansible IaC Pattern",description:'<MyImg src={require("./arms.jpeg").default} alt="AA robotic arm in an 80s sci-fi style installing server equipment into a rack within a modern data center."',date:"2025-07-14T00:00:00.000Z",formattedDate:"July 14, 2025",tags:[{label:"k8s",permalink:"/tags/k-8-s"},{label:"ansible",permalink:"/tags/ansible"},{label:"postgresql",permalink:"/tags/postgresql"},{label:"devops",permalink:"/tags/devops"}],readingTime:10.12,hasTruncateMarker:!0,authors:[{name:"Greg Glazewski",title:"Software Engineer @ GRAN Software Solutions GmbH",url:"https://www.linkedin.com/in/greg-glazewski-88390827",imageURL:"https://github.com/gglazewskigran.png",key:"gglazewskigran"}],frontMatter:{title:"Automating Production Postgres on Kubernetes: A PGO and Ansible IaC Pattern",authors:"gglazewskigran",tags:["k8s","ansible","postgresql","devops"],enableComments:!0},nextItem:{title:"Beyond SSH Tunnels: Secure K8s Access with WireGuard & Ansible",permalink:"/2025/07/04/k8s-wireguard-access"}},c={authorsImageUrls:[void 0]},p=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Section 1: Why Ansible for PGO Management?",id:"section-1-why-ansible-for-pgo-management",level:2},{value:"Section 2: Ansible Project Structure",id:"section-2-ansible-project-structure",level:2},{value:"Section 3: The Playbook - Laying the Groundwork &amp; Installing PGO",id:"section-3-the-playbook---laying-the-groundwork--installing-pgo",level:2},{value:"1. Create the Database Namespace",id:"1-create-the-database-namespace",level:3},{value:"2. Create the pgBackRest S3 Secret",id:"2-create-the-pgbackrest-s3-secret",level:3},{value:"3. Install the PGO Operator",id:"3-install-the-pgo-operator",level:3},{value:"Section 4: Provisioning the Postgres Cluster",id:"section-4-provisioning-the-postgres-cluster",level:2},{value:"Accessing the Secret from a Different Namespace",id:"accessing-the-secret-from-a-different-namespace",level:3},{value:"Section 5: The Main Playbook and Disaster Recovery",id:"section-5-the-main-playbook-and-disaster-recovery",level:2},{value:"Conclusion",id:"conclusion",level:2}],u={toc:p},g="wrapper";function d({components:e,...n}){return(0,r.yg)(g,(0,t.A)({},u,n,{components:e,mdxType:"MDXLayout"}),(0,r.yg)(s.A,{src:a(8677).A,alt:"AA robotic arm in an 80s sci-fi style installing server equipment into a rack within a modern data center.",title:"The future of IT infrastructure built with automation",mdxType:"MyImg"}),(0,r.yg)("p",null,"This guide details a production-grade, Infrastructure as Code (IaC) pattern for deploying the Crunchy Data Postgres Operator (PGO) on Kubernetes with Ansible. It's designed for experienced engineers managing their own infrastructure on platforms like K3s, not for those using managed cloud database services like RDS or Cloud SQL."),(0,r.yg)("p",null,"By wrapping PGO's Helm chart and cluster definitions in Ansible, you create a version-controlled, repeatable, and automated system. By the end, you will have a complete playbook that deploys PGO and provisions a Postgres cluster with production-ready, S3-backed backups."),(0,r.yg)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.yg)("p",null,"This guide assumes you are comfortable with the following:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Ansible:")," Playbook structure, variables, and the ",(0,r.yg)("inlineCode",{parentName:"li"},"kubernetes.core.helm")," and ",(0,r.yg)("inlineCode",{parentName:"li"},"kubernetes.core.k8s")," modules."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Kubernetes:")," A running cluster (K3s is our target), Namespaces, Secrets, CRDs, and PVCs."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Helm & PGO:")," Basic familiarity with managing Helm charts and the purpose of a Postgres Operator.")),(0,r.yg)("h2",{id:"section-1-why-ansible-for-pgo-management"},"Section 1: Why Ansible for PGO Management?"),(0,r.yg)("p",null,"While ",(0,r.yg)("inlineCode",{parentName:"p"},"helm")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"kubectl")," are effective, wrapping them in Ansible provides a declarative, auditable, and integrated system for production."),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Single Source of Truth:")," The playbook becomes the canonical definition of your Postgres setup, eliminating configuration drift and ensuring consistency across all environments."),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Orchestrate Dependencies:")," Codify the entire workflow in a single run: create namespaces, provision S3 secrets, install the operator, and then deploy the cluster. This avoids manual sequencing errors."),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Manage Secrets Securely:")," Use Ansible's power to fetch, process, and inject secrets from external sources (like a cloud secret manager) directly into Kubernetes, leveraging features like ",(0,r.yg)("inlineCode",{parentName:"li"},"no_log")," and Ansible Vault."),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Control the Full Lifecycle:")," The same playbook manages creation, upgrades, and configuration changes. Conditional logic allows you to handle different operational scenarios like disaster recovery from the same code base.")),(0,r.yg)("p",null,"In short, Ansible elevates your deployment from a series of manual commands to a coherent, version-controlled system. This not only ensures consistency but also dramatically lowers your Recovery Time Objective (RTO) by turning complex disaster recovery procedures into a single, reliable command."),(0,r.yg)("h2",{id:"section-2-ansible-project-structure"},"Section 2: Ansible Project Structure"),(0,r.yg)("p",null,"A logical project structure is essential for maintainability. We recommend organizing your files as follows. This separates concerns and makes the project easy to navigate."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"ansible_pgo/\n\u251c\u2500\u2500 inventory/\n\u2502   \u2514\u2500\u2500 hosts.ini\n\u251c\u2500\u2500 tasks/\n\u2502   \u251c\u2500\u2500 01_db_namespace.yaml\n\u2502   \u251c\u2500\u2500 02_pgbackrest_secret.yaml\n\u2502   \u251c\u2500\u2500 03_pgo_install.yaml\n\u2502   \u251c\u2500\u2500 04_init_db.yaml\n\u2502   \u2514\u2500\u2500 05_restore_db.yaml\n\u251c\u2500\u2500 production_vault.yaml\n\u2514\u2500\u2500 software.yaml\n")),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"software.yaml"),": The entrypoint playbook that orchestrates the entire deployment by including tasks in the correct order."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"inventory/"),": Defines your target hosts and groups for different environments (e.g., development, production)."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"tasks/"),": Contains the individual YAML files, each responsible for a specific, reusable action."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"*_vault.yaml"),": Your environment-specific, encrypted variable files for storing sensitive data like API keys and passwords, managed with Ansible Vault.")),(0,r.yg)("h2",{id:"section-3-the-playbook---laying-the-groundwork--installing-pgo"},"Section 3: The Playbook - Laying the Groundwork & Installing PGO"),(0,r.yg)("p",null,"The deployment is sequenced carefully. We first create the necessary Kubernetes resources\u2014the namespace for the database and the secret for S3 backups\u2014before installing the PGO operator itself. This ensures all dependencies are met."),(0,r.yg)("p",null,"Throughout the following tasks, you will see the ",(0,r.yg)("inlineCode",{parentName:"p"},'kubeconfig: "{{ k3s_kubeconfig_path }}"')," parameter. This variable specifies the path on the target server to the ",(0,r.yg)("inlineCode",{parentName:"p"},"kubeconfig")," file needed to authenticate with the Kubernetes API. For a standard K3s installation, this value is typically ",(0,r.yg)("inlineCode",{parentName:"p"},"/etc/rancher/k3s/k3s.yaml"),"."),(0,r.yg)("h3",{id:"1-create-the-database-namespace"},"1. Create the Database Namespace"),(0,r.yg)("p",null,"First, we ensure a dedicated namespace exists for our Postgres clusters. Note the use of ",(0,r.yg)("inlineCode",{parentName:"p"},"wait: true"),", which is crucial in an automated workflow to guarantee the namespace is created before Ansible proceeds to the next task."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'# tasks/01_db_namespace.yaml\n- name: Create the database namespace\n  kubernetes.core.k8s:\n    wait: true\n    kubeconfig: "{{ k3s_kubeconfig_path }}"\n    state: present\n    definition:\n      apiVersion: v1\n      kind: Namespace\n      metadata:\n        name: database\n')),(0,r.yg)("h3",{id:"2-create-the-pgbackrest-s3-secret"},"2. Create the pgBackRest S3 Secret"),(0,r.yg)("p",null,"Next, we create the secret that PGO will use to connect to an S3-compatible object store for backups. This task is a prime example of Ansible's power: it runs a shell command to fetch a key from an external service."),(0,r.yg)("p",null,"This task uses ",(0,r.yg)("inlineCode",{parentName:"p"},"delegate_to: localhost"),", which means ",(0,r.yg)("strong",{parentName:"p"},"the command to fetch the secret runs on your Ansible control node, not on the Kubernetes server"),". While this example uses the Scaleway CLI (",(0,r.yg)("inlineCode",{parentName:"p"},"scw"),"), the principle applies to any cloud provider. You would simply substitute the command with the equivalent for your provider (e.g., ",(0,r.yg)("inlineCode",{parentName:"p"},"aws")," or ",(0,r.yg)("inlineCode",{parentName:"p"},"gcloud"),"). Crucially, this requires you to have the appropriate CLI tool installed and configured on the machine where you run your playbook."),(0,r.yg)("p",null,"We recommend using a common Ansible Execution Environment. Let me know if you want a nice tutorial on it too :)"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'# tasks/02_pgbackrest_secret.yaml\n- name: Fetch pgBackRest encryption key from Scaleway Secret Manager\n  ansible.builtin.shell:\n    cmd: scw secret version access {{ pgbackrest_repo1_cipher_secret_id }} revision=1 -o json | jq -r .data\n  environment:\n    SCW_ACCESS_KEY: "{{ AWS_ACCESS_KEY_ID }}"\n    SCW_SECRET_KEY: "{{ AWS_SECRET_ACCESS_KEY }}"\n    SCW_DEFAULT_ORGANIZATION_ID: "{{ scaleway_organization_id }}"\n    SCW_DEFAULT_REGION: "{{ scaleway_region }}"\n  register: pgbackrest_repo1_cipher_pass_raw\n  changed_when: false\n  delegate_to: localhost\n  become: false # default user is "runner" and that\'s where scw is installed, so I don\'t want this to run as sudo\n  no_log: true\n\n- name: Create S3 credentials secret for pgBackRest\n  kubernetes.core.k8s:\n    kubeconfig: "{{ k3s_kubeconfig_path }}"\n    state: present\n    definition:\n      apiVersion: v1\n      kind: Secret\n      metadata:\n        name: pgo-s3-creds\n        namespace: database\n      type: Opaque\n      stringData:\n        s3.conf: |\n          [global]\n          repo1-s3-key={{ AWS_ACCESS_KEY_ID }}\n          repo1-s3-key-secret={{ AWS_SECRET_ACCESS_KEY }}\n          repo1-cipher-type=aes-256-cbc\n          repo1-cipher-pass={{ pgbackrest_repo1_cipher_pass_raw.stdout | trim | b64decode }}\n          repo1-retention-full=4\n')),(0,r.yg)("p",null,"A common mistake is creating this secret in the wrong namespace. The ",(0,r.yg)("inlineCode",{parentName:"p"},"pgo-s3-creds")," secret must exist in the ",(0,r.yg)("strong",{parentName:"p"},"same namespace where your ",(0,r.yg)("inlineCode",{parentName:"strong"},"PostgresCluster")," will be created")," (",(0,r.yg)("inlineCode",{parentName:"p"},"database"),"), not in the ",(0,r.yg)("inlineCode",{parentName:"p"},"postgres-operator")," namespace."),(0,r.yg)("p",null,"Two critical production-ready settings are defined here:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Backup Encryption:")," ",(0,r.yg)("inlineCode",{parentName:"li"},"repo1-cipher-pass")," ensures backups are encrypted at rest in S3."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Backup Retention:")," ",(0,r.yg)("inlineCode",{parentName:"li"},"repo1-retention-full=4")," tells ",(0,r.yg)("inlineCode",{parentName:"li"},"pgbackrest")," to keep the 4 most recent full backups, managing storage costs.")),(0,r.yg)("h3",{id:"3-install-the-pgo-operator"},"3. Install the PGO Operator"),(0,r.yg)("p",null,"With the prerequisites in place, we install PGO using the ",(0,r.yg)("inlineCode",{parentName:"p"},"kubernetes.core.helm")," module. We pin the ",(0,r.yg)("inlineCode",{parentName:"p"},"chart_version")," for repeatable builds and use ",(0,r.yg)("inlineCode",{parentName:"p"},"wait: true")," to ensure the Helm release is fully deployed."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'# tasks/03_pgo_install.yaml\n- name: Install Crunchy PGO from Helm chart\n  kubernetes.core.helm:\n    name: pgo\n    chart_ref: oci://[registry.developers.crunchydata.com/crunchydata/pgo](https://registry.developers.crunchydata.com/crunchydata/pgo)\n    chart_version: 5.8.2\n    release_namespace: postgres-operator\n    create_namespace: true\n    state: present\n    kubeconfig: "{{ k3s_kubeconfig_path }}"\n    wait: true\n    wait_timeout: 10m\n    values:\n      resources:\n        limits:\n          cpu: 1000m\n          memory: 512Mi\n        requests:\n          cpu: 100m\n          memory: 256Mi\n')),(0,r.yg)("p",null,"Note the ",(0,r.yg)("inlineCode",{parentName:"p"},"chart_ref")," format: ",(0,r.yg)("inlineCode",{parentName:"p"},"oci://..."),". This uses an OCI registry, the modern standard for distributing Helm charts, ensuring you pull from the official source."),(0,r.yg)("h2",{id:"section-4-provisioning-the-postgres-cluster"},"Section 4: Provisioning the Postgres Cluster"),(0,r.yg)("p",null,"Now we can define and create our actual Postgres database by applying a ",(0,r.yg)("inlineCode",{parentName:"p"},"PostgresCluster")," custom resource."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'# tasks/04_init_db.yaml\n- name: Create an empty PostgresCluster\n  kubernetes.core.k8s:\n    kubeconfig: "{{ k3s_kubeconfig_path }}"\n    state: present\n    definition:\n      apiVersion: [postgres-operator.crunchydata.com/v1beta1](https://postgres-operator.crunchydata.com/v1beta1)\n      kind: PostgresCluster\n      metadata:\n        name: your-project-db\n        namespace: database\n      spec:\n        postgresVersion: 16\n        instances:\n          - name: instance1\n            replicas: 1 # configure this for your prod env\n            dataVolumeClaimSpec:\n              accessModes:\n                - "ReadWriteOnce"\n              resources:\n                requests:\n                  storage: 5Gi # configure this for your prod env\n        backups:\n          pgbackrest:\n            repos:\n              - name: repo1 #repoN is required naming convention\n                s3:\n                  bucket: "{{ pgo_s3_bucket }}"\n                  endpoint: "{{ pgo_s3_endpoint }}"\n                  region: "{{ pgo_s3_region }}"\n                schedules:\n                  full: "0 1 * * 0"\n                  incremental: "0 1 * * *"\n            configuration:\n              - secret:\n                  name: pgo-s3-creds\n        users:\n          - name: your_project_user\n            databases:\n              - your_project_db\n')),(0,r.yg)("p",null,"Let's break down the key parts of this ",(0,r.yg)("inlineCode",{parentName:"p"},"spec"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"postgresVersion: 16")),": Specifies the desired major version of Postgres."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"instances")),": Defines a single primary (",(0,r.yg)("inlineCode",{parentName:"li"},"replicas: 1"),") with a 5Gi Persistent Volume Claim (PVC)."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"backups.pgbackrest.repos")),": Configures the connection to our S3 bucket."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"schedules")),": Defines cron schedules for a full backup (weekly on Sunday) and incremental backups (daily). This, combined with continuous WAL archiving, provides robust Point-in-Time Recovery (PITR). By default, Postgres archives WAL files when they reach 16MB or after 60 seconds, whichever comes first, ensuring minimal data loss."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("inlineCode",{parentName:"strong"},"users")),": Automatically creates a Postgres role (",(0,r.yg)("inlineCode",{parentName:"li"},"your_project_user"),") and a database (",(0,r.yg)("inlineCode",{parentName:"li"},"your_project_db"),"). The operator generates a Kubernetes secret named ",(0,r.yg)("inlineCode",{parentName:"li"},"{cluster-name}-pguser-{user-name}")," (e.g., ",(0,r.yg)("inlineCode",{parentName:"li"},"your-project-db-pguser-your_project_user"),") containing the password.")),(0,r.yg)("h3",{id:"accessing-the-secret-from-a-different-namespace"},"Accessing the Secret from a Different Namespace"),(0,r.yg)("p",null,"Your application likely runs in a different namespace (e.g., ",(0,r.yg)("inlineCode",{parentName:"p"},"app-namespace"),") and will need permission to read the database secret from the ",(0,r.yg)("inlineCode",{parentName:"p"},"database")," namespace. To grant this access securely, you must create a ",(0,r.yg)("inlineCode",{parentName:"p"},"ClusterRole")," and a ",(0,r.yg)("inlineCode",{parentName:"p"},"RoleBinding"),"."),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Create a ",(0,r.yg)("inlineCode",{parentName:"strong"},"ClusterRole"),":")),(0,r.yg)("p",{parentName:"li"},"Notice no namespace defined here as it\u2019s cluster wide."),(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: secret-reader\nrules:\n- apiGroups: [""]\n  resources: ["secrets"]\n  resourceNames: ["your-project-db-pguser-your_project_user"]\n  verbs: ["get"]\n'))),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Create a ",(0,r.yg)("inlineCode",{parentName:"strong"},"RoleBinding"),":")),(0,r.yg)("p",{parentName:"li"},"RoleBinding is in the same namespace as your database but it can specify a different namespace for its subjects."),(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: read-db-secret-from-app-ns\n  namespace: database\nsubjects:\n- kind: ServiceAccount\n  name: default # Or your app's service account\n  namespace: app-namespace\nroleRef:\n  kind: ClusterRole\n  name: secret-reader\n  apiGroup: rbac.authorization.k8s.io\n")))),(0,r.yg)("h2",{id:"section-5-the-main-playbook-and-disaster-recovery"},"Section 5: The Main Playbook and Disaster Recovery"),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"software.yaml")," playbook is the conductor. It uses ",(0,r.yg)("inlineCode",{parentName:"p"},"ansible.builtin.include_tasks")," to execute our task files in sequence and includes conditional logic for disaster recovery."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"# software.yaml\n- name: Deploy PGO and Postgres Cluster\n  hosts: all\n  become: true\n  vars_files:\n    - ../{{ stage }}_vault.yaml # e.g. production_vault.yaml\n  vars:\n    k3s_kubeconfig_path: /etc/rancher/k3s/k3s.yaml\n    restore_db: false # Set to true for disaster recovery\n\n  tasks:\n    - name: Ensure database namespace exists\n      ansible.builtin.include_tasks: tasks/01_db_namespace.yaml\n\n    - name: Create pgBackRest S3 secret\n      ansible.builtin.include_tasks: tasks/02_pgbackrest_secret.yaml\n\n    - name: Install PGO operator\n      ansible.builtin.include_tasks: tasks/03_pgo_install.yaml\n\n    - name: Provision initial postgres cluster\n      ansible.builtin.include_tasks: tasks/04_init_db.yaml\n      when: not restore_db | bool\n\n    - name: Restore postgres cluster from backup\n      ansible.builtin.include_tasks: tasks/05_restore_db.yaml\n      when: restore_db | bool\n")),(0,r.yg)("p",null,"This logic is controlled by the ",(0,r.yg)("inlineCode",{parentName:"p"},"restore_db")," variable. When ",(0,r.yg)("inlineCode",{parentName:"p"},"false"),", it runs ",(0,r.yg)("inlineCode",{parentName:"p"},"init_db.yaml"),". When ",(0,r.yg)("inlineCode",{parentName:"p"},"true"),", it runs ",(0,r.yg)("inlineCode",{parentName:"p"},"restore_db.yaml")," instead."),(0,r.yg)("p",null,"Here is the task for restoring from a backup:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'# tasks/05_restore_db.yaml\n- name: Create a PostgresCluster that restores from backup\n  kubernetes.core.k8s:\n    kubeconfig: "{{ k3s_kubeconfig_path }}"\n    state: present\n    definition:\n      apiVersion: [postgres-operator.crunchydata.com/v1beta1](https://postgres-operator.crunchydata.com/v1beta1)\n      kind: PostgresCluster\n      metadata:\n        name: your-project-db\n        namespace: database\n      spec:\n        # This section triggers the restore\n        dataSource:\n          pgbackrest:\n            stanza: db\n            repo:\n              name: repo1\n            configuration:\n              - secret:\n                  name: pgo-s3-creds\n            global:\n              repo1-path: /backup/repo1\n        # The rest of the spec is identical to the init_db task\n        # to ensure the restored cluster has the same configuration.\n        postgresVersion: 16\n        instances:\n          - name: instance1\n            replicas: 1\n            dataVolumeClaimSpec:\n              accessModes:\n                - "ReadWriteOnce"\n              resources:\n                requests:\n                  storage: 5Gi\n        backups:\n          pgbackrest:\n            repos:\n              - name: repo1\n                s3:\n                  bucket: "{{ pgo_s3_bucket }}"\n                  endpoint: "{{ pgo_s3_endpoint }}"\n                  region: "{{ pgo_s3_region }}"\n                schedules:\n                  full: "0 1 * * 0"\n                  incremental: "0 1 * * *"\n            configuration:\n              - secret:\n                  name: pgo-s3-creds\n        users:\n          - name: your_project_user\n            databases:\n              - your_project_db\n')),(0,r.yg)("p",null,"The critical difference is the ",(0,r.yg)("inlineCode",{parentName:"p"},"spec.dataSource.pgbackrest")," section. This instructs PGO to provision a new cluster and then immediately perform a restore from the specified S3 backup repository. This allows you to rebuild your entire database with a single command: ",(0,r.yg)("inlineCode",{parentName:"p"},'ansible-playbook software.yaml -e "restore_db=true"'),"."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"If there is nothing to restore, the database will not start.")),(0,r.yg)("p",null,"This is why you have to init your database first to create the starting point for the recovery."),(0,r.yg)("p",null,"Fine-tuning the connection between pgBackRest and your S3 may take some time and be tricky. Check logs in your postgres-operator namespace to see what\u2019s going on. If you see error code 37 or 39, it means that the S3 connection didn\u2019t work (anything from wrong keys, secrets, bucket, policies, regions etc)."),(0,r.yg)("p",null,"Debug it by creating stanza manually:"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"kubectl exec -n database your-project-db-repo-host-0 -c pgbackrest -- pgbackrest stanza-create --log-level-console=debug")),(0,r.yg)("p",null,"Be patient. If you configured everything properly, it still will take a while before your cluster is up and running after a recovery (it takes around 3 minutes for me before I see postgres pods up). Watch pods in your namespace to see what\u2019s going on."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"If you init database with a S3 bucket that already contains backups - they will be deleted!")),(0,r.yg)("p",null,"Make sure to use versioning in your S3 bucket!"),(0,r.yg)("h2",{id:"conclusion"},"Conclusion"),(0,r.yg)("p",null,"By wrapping the Crunchy Data Postgres Operator in Ansible, you transform a series of manual commands into a robust, version-controlled, and automated system. This pattern provides a single source of truth for your database infrastructure, codifies dependencies, manages secrets securely, and handles the full lifecycle from initial provisioning to disaster recovery. This approach significantly reduces the risk of configuration drift and manual error, providing the reliability required for production workloads on Kubernetes."))}d.isMDXComponent=!0},8677:(e,n,a)=>{a.d(n,{A:()=>t});const t=a.p+"assets/images/arms-56e4735a35515ab76442e09cf2b9bb54.jpeg"},9041:(e,n,a)=>{a.d(n,{A:()=>r});var t=a(6540);const r=function(e){const n=e.width?{width:`${e.width}px`}:{};return void 0!==e.title?t.createElement("center",null,t.createElement("figure",null,t.createElement("img",{src:e.src,alt:e.alt,style:n}),t.createElement("figcaption",{style:{textAlign:"center"}},e.title))):t.createElement("img",{src:e.src,alt:e.alt,style:n})}}}]);